{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from utils import label_map_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='ssd_mobilenet_v1_coco_2018_01_28'  #model name\n",
    "fps = 24 # change it with your input video fps\n",
    "width = 650#change it with your input video width\n",
    "height = 550 # change it with your input vide height\n",
    "is_color_recognition_enabled = 0 # set it to 1 for enabling the color prediction for the detected objects\n",
    "roi = 250#roi line position\n",
    "deviation = 3 # the constant that represents the object counting area\n",
    "input_video = \"Vclip.mp4\"\n",
    "    \n",
    "model_found = 0\n",
    "\n",
    "for file in glob.glob(\"*\"):\n",
    "    if (file == model_name):\n",
    "        model_found = 1\n",
    "model_name = model_name\n",
    "model_file = model_name + '.tar.gz'\n",
    "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "path_to_ckpt = model_name + '/frozen_inference_graph.pb'\n",
    "\n",
    "path_to_labels = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "num_classes = 90\n",
    "\n",
    "if (model_found == 0):\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(download_base + model_file, model_file)\n",
    "    tar_file = tarfile.open(model_file)\n",
    "    for file in tar_file.getmembers():\n",
    "        file_name = os.path.basename(file.name)\n",
    "        if 'frozen_inference_graph.pb' in file_name:\n",
    "            tar_file.extract(file, os.getcwd())\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(path_to_ckpt, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "label_map = label_map_util.load_labelmap(path_to_labels)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "def object_detect_count(input_video, detection_graph, category_index, is_color_recognition_enabled, fps, width, height, roi, deviation):\n",
    "        total_passed_vehicle = 0        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "        total_passed_vehicle = 0\n",
    "        counting_mode = \"...\"\n",
    "        width_heigh_taken = True\n",
    "        with detection_graph.as_default():\n",
    "          with tf.Session(graph=detection_graph) as sess:\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "            while(cap.isOpened()):\n",
    "                ret, frame = cap.read()                \n",
    "\n",
    "                if not  ret:\n",
    "                    print(\"end of the video file...\")\n",
    "                    break\n",
    "                \n",
    "                input_frame = frame\n",
    "\n",
    "                image_np_expanded = np.expand_dims(input_frame, axis=0)\n",
    "\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "                counter, csv_line, counting_mode = vis_util.visualize_boxes_and_labels_on_image_array_y_axis(cap.get(1),\n",
    "                                                                                                             input_frame,\n",
    "                                                                                                             2,\n",
    "                                                                                                             is_color_recognition_enabled,\n",
    "                                                                                                             np.squeeze(boxes),\n",
    "                                                                                                             np.squeeze(classes).astype(np.int32),\n",
    "                                                                                                             np.squeeze(scores),\n",
    "                                                                                                             category_index,\n",
    "                                                                                                             y_reference = roi,\n",
    "                                                                                                             deviation = deviation,\n",
    "                                                                                                             use_normalized_coordinates=True,\n",
    "                                                                                                             line_thickness=4)\n",
    "\n",
    "                if counter == 1:                  \n",
    "                  cv2.line(input_frame, (0, roi), (width, roi), (0, 0xFF, 0), 5)\n",
    "                else:\n",
    "                  cv2.line(input_frame, (0, roi), (width, roi), (0, 0, 0xFF), 5)\n",
    "                \n",
    "                total_passed_vehicle = total_passed_vehicle + counter\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(\n",
    "                    input_frame,\n",
    "                    'Detected Vehicles: ' + str(total_passed_vehicle),\n",
    "                    (10, 35),\n",
    "                    font,\n",
    "                    0.8,\n",
    "                    (0, 0xFF, 0xFF),\n",
    "                    2,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    )               \n",
    "                \n",
    "                cv2.putText(\n",
    "                    input_frame,\n",
    "                    'ROI Line',\n",
    "                    (545, roi-10),\n",
    "                    font,\n",
    "                    0.6,\n",
    "                    (0, 0, 0xFF),\n",
    "                    2,\n",
    "                    cv2.LINE_AA,\n",
    "                    )\n",
    "                cv2.imshow('object counting',input_frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "object_detect_count(input_video, detection_graph, category_index, is_color_recognition_enabled, fps, width, height, roi, deviation) # counting all the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
